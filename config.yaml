# Configuration

# ==================================== Feishu(Lark) Configuration ==================================== #
# ------------------------------------------------------------------------------------------------------------ #
# Feishu(Lark) Bot Webhook URL
webhook_url: 'https://open.feishu.cn/open-apis/bot/v2/hook/XXXXX'  # TODO: Change to your Webhook URL

# Feishu(Lark) Webhook Secret (for signature verification)
webhook_secret: ''  # TODO: Set your webhook secret (leave empty if not using signature verification)

# Feishu(Lark) Card Template
template_id: 'ArXivToday.card'  # TODO: Change to your template_id
template_version_name: '1.0.0'  # TODO: Change to your template_version_name
# ------------------------------------------------------------------------------------------------------------ #


# ==================================== Paper Configuration ==================================== #
# ------------------------------------------------------------------------------------------------------------ #
tag: 'Embodied AI'  # Tag for Feishu(Lark) Card

category_list:  # arXiv categories to search for papers
  - cs.CV  # Computer Vision and Pattern Recognition
  - cs.RO  # Robotics
  - cs.LG  # Machine Learning

# ------------------------------------------------------------------------------------------------------------ #


# ==================================== LLM Service Configuration ==================================== #
# ------------------------------------------------------------------------------------------------------------ #

# LLM Server Config
model: ''
base_url: ''  # NOTE: For ollama, need to add '/v1' at the end of the OLLAMA_HOST URL
api_key: 'openai'

#### >>> LLM Server Config EXAMPLE >>> ####

## 1. For Ollama Server ##
# model: 'qwen2.5:7b'
# base_url: 'http://localhost:11434/v1'  # NOTE: For ollama, need to add '/v1' at the end of the OLLAMA_HOST URL
# api_key: 'ollama'  # Any non-empty string works (Ollama does not require authentication)

## 2. For Other OpenAI SDK-Compatibale LLM Server ##
# model: 'gpt-4o-mini'
# base_url: 'https://api.openai.com/v1'
# api_key: 'sk-xxxxx'

#### <<< LLM Server Config EXAMPLE <<< ####

# ------------------------------------------------------------------------------------------------------------ #

# Use LLM for More Accurate Paper Filtering
use_llm_for_filtering: true  # Set to false to disable LLM-based filtering

#### >>> LLM-Based Paper Filtering >>> ####
# If set to true, `paper_to_hunt.md` file in the project root directory will be used for LLM-based filtering.
# You can modify the prompt in `paper_to_hunt.md` to describe the paper you want to hunt for.
#### <<< LLM-Based Paper Filtering <<< ####

# ------------------------------------------------------------------------------------------------------------ #

# Use LLM for Paper Abstract Translation
use_llm_for_translation: true  # Set to false to disable LLM-based translation

# ------------------------------------------------------------------------------------------------------------ #
